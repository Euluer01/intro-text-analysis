---
output: html_document
bibliography: ../references.bib
---

# Meeting 1

## Overview

1.  Review resources
2.  Installing RStudio/Using the cluster
3.  What is quantitative textual analysis?
4.  What is corpus linguistics?
5.  Getting started
6.  Homework

## Review Resources

-   [Coursera](https://www.coursera.org/learn/r-programming)
-   [Interactive Notebook](../r-review/00_r-review.Rmd)

## Installing RStudio

Tufts [instructions](https://sites.tufts.edu/datalab/installing-r-and-rstudio/) for installing R and RStudio.

## What is quantitative textual analysis?

> Unlike other sources of information such as mythology, philosophy or art, **science** relies on the systematic collection of empirical data and testing of theories and hypotheses. [@Brezina2018 2; emphasis original]

More tactfully (citing Popper 2005 [1935]):

> A scientific statement or theory [is] something that can in principle be falsified.... In other words, we can call a statement or theory scientific only if it can be tested empirically. [@Brezina2018: 2]

-   How do we qualify these statements?
-   Are there problems with viewing texts in this way?
-   Conversely, are there virtues in understanding textual data in this light?

## What is corpus linguistics?

> **Corpus linguistics** is a scientific method of language analysis. It requires the analyst to provide empirical evidence in the form of data drawn from language corpora in support of any statement made about language. [@Brezina2018: 2]

## Getting started

In this directory, you will find three text files containing the openings to Xenophon's *Apology*, Caesar's *De Bello Gallico*, and Jane Austen's *Pride and Prejudice*.

Let's start with *Pride and Prejudice*. Run the code block below to load the contents of the file into memory.

```{r}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # make sure that our working directory is correctly set
txt <- file("austen-pride-and-prejudice.txt") # open a connection to the file
austen <- readLines(txt) # read the file line by line
close(txt) # close the connection

austen # sanity check: is the output what we think it should be?
```
Hm, looks like we have an extra blank line. We don't want to deal with paragraphs just yet, so can we clean that up?

```{r}
austen[which(austen != "")]
```

That's better. Can you describe how this function works? Let's use RStudio's built-in `help` function to walk through the steps.

```{r}
help("[")
```

Okay, so the `[` signals the start of an action on an object, which in this case is the three rows of strings that we've stored in the variable `austen`.

What happens if we try something simple, like `austen[1]`?

```{r}
austen[1]
```

We get the first line -- nice!

But what is this `which` function?

```{r}
help("which")
```

Makes sense: `which` returns the indices of an object **which** are true for our logical test. How would we translate the English question, "Which rows of `austen` are not empty?" to a call to `which`?

```{r}
which(austen != "")
```

What does this result tell us? In English, "Rows `1` and `3` of `austen` are not equal (`!=`) to the empty string (`""`).

We can now put it all together again to say, "Give me the _values_ of the rows in `austen` that are not empty."

```{r}
austen[which(austen != "")]
```

### So what?

These exercises are just the first steps towards using corpus linguistics in your interpretive practice. The main textbook that we'll be using, @Brezina2018, doesn't do a great job of providing hands-on exercises and instead wants to focus on the statics side of things. We're going to try to cover both the hands-on programming side and the statistical side in this course.

To that end, let's turn our attention to some terms and techniques that we'll need to cover.

- Corpus/sample: Collections of data. Most of the time, a "corpus" is meant to be large, like all Greek literature before 300 AD. But relatively small corpora --- like, say, all of 5th-century Athenian tragedy --- can prove useful as well.
- Dataset: Collection of findings within the data of a corpus.
- Variable: 
  - Linguistic variables: These are, generally, the things we want to measure.
  - Explanatory ("independent") variables: Descriptors for where we find linguistic variables (see [@Brezina2018 6--7]).
  
### Different kinds of variables

Variables come in three varieties: nominal, ordinal, and scale [@Brezina2018 7]:

- **Nominal** variables "represent different categories into which the cases in a dataset can be grouped; there is no order or hierarchy between the categories."
  - Ex. speaker's gender
- **Ordinal** variables, like nominal variables, can be used for grouping data, but they "can be ordered according to some inherent hierarchy."
  - Ex. speaker's foreign language proficiency
- **Scale** variables "[show] the quantity of a particular feature; ... [they] can be added, subtracted, multiplied, and divided, because they represent measurable quantities, not just rank orders."
  - Ex. relative frequency of first-person pronouns in a speaker's speech.
  
## Measures of central tendency

- Frequency distributions and averages help us determine outliers in our data.
- What are the measures of central tendency with which you're familiar?
- How are they calculated?
- What is a normal distribution?

## Dispersion measures

Define the following:

- Range_1
- Interquartile range
- Standard deviation

## Statistical tests

- How do we determine if a result is statistically signficant?

## Biases

According to @Brezina2018 [17--18], with what biases should we be concerned?

What biases might be present in our tiny test corpus (`austen`) right now?

## Homework

1. @Brezina2018 1.7 Exercises (pp. 32--36); you can skip Exercise 1.
2. Practice loading the included Greek and Latin texts into RStudio. What issues do you encounter?
